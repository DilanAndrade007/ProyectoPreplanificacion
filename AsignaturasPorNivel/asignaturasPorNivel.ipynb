{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "696cc912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlsxwriter\n",
      "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
      "   ---------------------------------------- 0.0/172.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/172.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/172.3 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/172.3 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 20.5/172.3 kB 165.2 kB/s eta 0:00:01\n",
      "   ---- ---------------------------------- 20.5/172.3 kB 165.2 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 41.0/172.3 kB 196.9 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/172.3 kB 252.2 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 122.9/172.3 kB 450.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 172.3/172.3 kB 576.9 kB/s eta 0:00:00\n",
      "Installing collected packages: xlsxwriter\n",
      "Successfully installed xlsxwriter-3.2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df7e645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesado: data\\malla_administracion_empresas.pdf -> outputs/malla_administracion_empresas_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_agroindustria.pdf -> outputs/malla_agroindustria_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_ambiental.pdf -> outputs/malla_ambiental_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_ciencia_datos_IA.pdf -> outputs/malla_ciencia_datos_IA_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_civil.pdf -> outputs/malla_civil_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_computacion.pdf -> outputs/malla_computacion_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_economia.pdf -> outputs/malla_economia_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_electricidad.pdf -> outputs/malla_electricidad_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_electronica_automatizacion.pdf -> outputs/malla_electronica_automatizacion_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_fisica.pdf -> outputs/malla_fisica_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_geologia.pdf -> outputs/malla_geologia_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_matematica_aplicada.pdf -> outputs/malla_matematica_aplicada_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_matemática.pdf -> outputs/malla_matemática_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_materiales.pdf -> outputs/malla_materiales_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_mecanica.pdf -> outputs/malla_mecanica_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_mecatrónica.pdf -> outputs/malla_mecatrónica_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_petroleos.pdf -> outputs/malla_petroleos_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_produccion.pdf -> outputs/malla_produccion_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_quimica.pdf -> outputs/malla_quimica_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_sistemas_informacion.pdf -> outputs/malla_sistemas_informacion_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_software.pdf -> outputs/malla_software_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_tecnologias_informacion.pdf -> outputs/malla_tecnologias_informacion_codigos_por_nivel.csv\n",
      "Procesado: data\\malla_telecomunicaciones.pdf -> outputs/malla_telecomunicaciones_codigos_por_nivel.csv\n",
      "✅ Listo. Consolidado en outputs/todas_mallas_codigos.csv\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "import os\n",
    "import statistics\n",
    "\n",
    "# ===================== PARÁMETROS AJUSTABLES =====================\n",
    "FOLDER_PATH = \"data/\"\n",
    "OUTPUT_FOLDER = \"outputs/\"\n",
    "RIGHT_CUT_FRAC = 0.74          # corte para ignorar columna derecha (x1 <= width * RIGHT_CUT_FRAC)\n",
    "LEVEL_LEFT_MARGIN_FRAC = 0.08  # para detectar los dígitos grandes de nivel a la izquierda\n",
    "HEIGHT_MIN_FRAC = 0.88         # descarta \"words\" cuyo alto < (mediana_alto * este_factor)\n",
    "MIN_HEIGHT_PX = 7.5            # umbral de seguridad: si la mediana falla, usa este mínimo absoluto\n",
    "# ================================================================\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# PDFs a procesar\n",
    "pdf_files = glob.glob(os.path.join(FOLDER_PATH, \"*.pdf\"))\n",
    "\n",
    "# Regex de códigos: 4 letras + 3 dígitos\n",
    "CODE_RE = re.compile(r\"\\b[A-Z]{4}\\d{3}\\b\")\n",
    "\n",
    "# Mapa de símbolos a espacio para normalizar (flechas, guiones, bullets)\n",
    "ARROW_CHARS = [\n",
    "    \"→\",\"⇒\",\"➔\",\"⟶\",\"⟼\",\"⟿\",\"↦\",\"↠\",\"➤\",\"▶\",\"❯\",\"›\",\"»\",\n",
    "    \"-\", \"—\", \"–\", \"·\", \"•\", \"‣\", \"∙\", \"·\"\n",
    "]\n",
    "ARROW_TABLE = str.maketrans({ch: \" \" for ch in ARROW_CHARS})\n",
    "\n",
    "def normalize_token(txt: str) -> str:\n",
    "    # Limpia flechas y símbolos, compacta espacios\n",
    "    txt = (txt or \"\").translate(ARROW_TABLE)\n",
    "    txt = re.sub(r\"\\s+\", \" \", txt.strip())\n",
    "    return txt\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "for pdf_path in pdf_files:\n",
    "    file_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    levels_codes = defaultdict(list)\n",
    "    carrera_name = \"DESCONOCIDA\"\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # ------ Carrera ------\n",
    "        first_text = pdf.pages[0].extract_text() or \"\"\n",
    "        m = re.search(r\"Carrera:\\s*(.+)\", first_text, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            carrera_name = m.group(1).strip()\n",
    "\n",
    "        for page in pdf.pages:\n",
    "            width, height = page.width, page.height\n",
    "\n",
    "            # Extraemos palabras con coordenadas\n",
    "            words = page.extract_words(\n",
    "                x_tolerance=2, y_tolerance=2,\n",
    "                keep_blank_chars=False, use_text_flow=True\n",
    "            )\n",
    "\n",
    "            # Ignorar columna derecha\n",
    "            right_cut = width * RIGHT_CUT_FRAC\n",
    "            left_words = [w for w in words if w[\"x1\"] <= right_cut]\n",
    "\n",
    "            # ------------------ FILTRO POR TAMAÑO ------------------\n",
    "            # Calculamos la mediana del alto de los words (proxy de font-size)\n",
    "            heights = [(w[\"bottom\"] - w[\"top\"]) for w in left_words if w[\"bottom\"] > w[\"top\"]]\n",
    "            if heights:\n",
    "                med_h = statistics.median(heights)\n",
    "                height_threshold = max(med_h * HEIGHT_MIN_FRAC, MIN_HEIGHT_PX)\n",
    "            else:\n",
    "                height_threshold = MIN_HEIGHT_PX\n",
    "\n",
    "            # Dejamos solo words \"grandes\" (evita códigos chiquitos de flechas/prerrequisitos)\n",
    "            left_words_big = [w for w in left_words if (w[\"bottom\"] - w[\"top\"]) >= height_threshold]\n",
    "\n",
    "            # ------------------ DETECCIÓN DE NIVELES ------------------\n",
    "            level_markers = [\n",
    "                {\"text\": w[\"text\"], \"y\": (w[\"top\"] + w[\"bottom\"]) / 2}\n",
    "                for w in left_words_big\n",
    "                if w[\"text\"] in list(\"123456789\") and w[\"x0\"] < width * LEVEL_LEFT_MARGIN_FRAC\n",
    "            ]\n",
    "            level_markers.sort(key=lambda d: d[\"y\"])\n",
    "\n",
    "            # Deduplicar por proximidad vertical\n",
    "            dedup_levels = []\n",
    "            for lm in level_markers:\n",
    "                if not dedup_levels or abs(lm[\"y\"] - dedup_levels[-1][\"y\"]) > 8:\n",
    "                    dedup_levels.append(lm)\n",
    "\n",
    "            # Rango Y por nivel\n",
    "            ranges = []\n",
    "            for i, lm in enumerate(dedup_levels):\n",
    "                y_top = lm[\"y\"] - 24\n",
    "                y_bottom = (dedup_levels[i+1][\"y\"] - 24) if (i+1 < len(dedup_levels)) else height\n",
    "                try:\n",
    "                    lvl = int(lm[\"text\"])\n",
    "                    ranges.append((lvl, y_top, y_bottom))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # ------------------ EXTRACCIÓN DE CÓDIGOS ------------------\n",
    "            # Normalizamos texto (para no perder códigos pegados a flechas/símbolos)\n",
    "            for w in left_words_big:\n",
    "                cleaned = normalize_token(w[\"text\"]).upper()\n",
    "                # Buscar TODAS las coincidencias (si vienen pegadas)\n",
    "                for tok in re.findall(r\"[A-Z]{4}\\d{3}\", cleaned):\n",
    "                    if CODE_RE.fullmatch(tok):\n",
    "                        y_center = (w[\"top\"] + w[\"bottom\"]) / 2\n",
    "                        # Asignar por nivel según rango vertical\n",
    "                        for lvl, y0, y1 in ranges:\n",
    "                            if y0 <= y_center < y1:\n",
    "                                levels_codes[lvl].append(tok)\n",
    "                                break\n",
    "\n",
    "    # Limpiar duplicados por nivel manteniendo orden\n",
    "    for lvl in levels_codes:\n",
    "        seen = set()\n",
    "        ordered = []\n",
    "        for c in levels_codes[lvl]:\n",
    "            if c not in seen:\n",
    "                ordered.append(c)\n",
    "                seen.add(c)\n",
    "        levels_codes[lvl] = ordered\n",
    "\n",
    "    # Armar filas\n",
    "    rows = []\n",
    "    for lvl in sorted(levels_codes.keys()):\n",
    "        for code in levels_codes[lvl]:\n",
    "            rows.append({\n",
    "                \"archivo\": file_name,\n",
    "                \"carrera\": carrera_name,\n",
    "                \"nivel\": lvl,\n",
    "                \"codigo\": code\n",
    "            })\n",
    "\n",
    "    # Guardar por archivo\n",
    "    df = pd.DataFrame(rows).sort_values([\"nivel\", \"codigo\"]).reset_index(drop=True)\n",
    "    out_csv = os.path.join(OUTPUT_FOLDER, f\"{file_name}_codigos_por_nivel.csv\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"Procesado: {pdf_path} -> {out_csv}\")\n",
    "\n",
    "    all_rows.extend(rows)\n",
    "\n",
    "# Consolidado\n",
    "df_all = pd.DataFrame(all_rows).sort_values([\"archivo\", \"nivel\", \"codigo\"]).reset_index(drop=True)\n",
    "df_all.to_csv(os.path.join(OUTPUT_FOLDER, \"todas_mallas_codigos.csv\"), index=False)\n",
    "print(\"✅ Listo. Consolidado en outputs/todas_mallas_codigos.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffe62b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo generado con observaciones en: outputs/Reporte_AsignaturasPorNivel.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar la base de profesores (con varias columnas)\n",
    "profesores_df = pd.read_excel(\"data/asignaturas.xlsx\")\n",
    "\n",
    "# Renombramos la columna de código para facilidad\n",
    "profesores_df = profesores_df.rename(columns={\"SII - Código Materia\": \"codigo\"})\n",
    "\n",
    "# Cargar el consolidado de mallas\n",
    "mallas_df = pd.read_csv(\"outputs/todas_mallas_codigos.csv\")\n",
    "\n",
    "# Unimos para conocer nivel y carrera\n",
    "merged = profesores_df.merge(\n",
    "    mallas_df[[\"codigo\", \"nivel\", \"carrera\"]],\n",
    "    on=\"codigo\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Diccionario de observaciones por profesor\n",
    "observaciones = {}\n",
    "for nombre, grupo in merged.groupby(\"Nombre\"):\n",
    "    problemas = []\n",
    "    for (nivel, carrera), sub in grupo.groupby([\"nivel\", \"carrera\"]):\n",
    "        if len(sub) > 1:  # conflicto detectado\n",
    "            codigos = \", \".join(sub[\"codigo\"].tolist())\n",
    "            problemas.append(\n",
    "                f\"El profesor tiene las materias {codigos} en el mismo nivel {nivel} de la malla de {carrera}\"\n",
    "            )\n",
    "    observaciones[nombre] = \" | \".join(problemas) if problemas else \"\"\n",
    "\n",
    "# Agregar columna Observaciones (sin borrar las demás columnas)\n",
    "profesores_df[\"Observaciones\"] = profesores_df[\"Nombre\"].map(observaciones)\n",
    "\n",
    "# ======== Exportar a Excel con wrap text y filtros ========\n",
    "output_file = \"outputs/Reporte_AsignaturasPorNivel.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
    "    sheet_name = \"Validación\"\n",
    "    profesores_df.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "    # Índices para autofiltro: desde (fila0,col0) a (filaN,colM)\n",
    "    n_rows, n_cols = profesores_df.shape\n",
    "    worksheet.autofilter(0, 0, n_rows, n_cols - 1)  # filtros por columna\n",
    "    worksheet.freeze_panes(1, 0)  # congela la primera fila\n",
    "\n",
    "    # Formato de wrap text para Observaciones\n",
    "    wrap_fmt = workbook.add_format({\n",
    "        \"text_wrap\": True,\n",
    "        \"valign\": \"top\"   # alinear arriba para textos largos\n",
    "    })\n",
    "\n",
    "    # Encontrar el índice de la columna Observaciones y darle ancho + wrap\n",
    "    obs_col_idx = list(profesores_df.columns).index(\"Observaciones\")\n",
    "    worksheet.set_column(obs_col_idx, obs_col_idx, 60, wrap_fmt)\n",
    "\n",
    "    # (Opcional) ancho cómodo para el resto de columnas\n",
    "    # worksheet.set_column(0, n_cols - 2, 18)\n",
    "\n",
    "print(f\"✅ Archivo generado con observaciones en: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77c0210f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo generado con observaciones en: outputs/Reporte_AsignaturasPorNivel.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar la base de profesores (con varias columnas)\n",
    "profesores_df = pd.read_excel(\"data/asignaturas.xlsx\")\n",
    "\n",
    "# Renombramos la columna de código para facilidad\n",
    "profesores_df = profesores_df.rename(columns={\"SII - Código Materia\": \"codigo\"})\n",
    "\n",
    "# Cargar el consolidado de mallas\n",
    "mallas_df = pd.read_csv(\"outputs/todas_mallas_codigos.csv\")\n",
    "\n",
    "# Unimos para conocer nivel y carrera\n",
    "merged = profesores_df.merge(\n",
    "    mallas_df[[\"codigo\", \"nivel\", \"carrera\"]],\n",
    "    on=\"codigo\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Diccionario de observaciones por profesor\n",
    "observaciones = {}\n",
    "\n",
    "for nombre, grupo in merged.groupby(\"Nombre\", dropna=False):\n",
    "    problemas = []\n",
    "    # Evita NaN en nivel/carrera\n",
    "    grupo_ok = grupo.dropna(subset=[\"nivel\", \"carrera\"], how=\"any\")\n",
    "\n",
    "    for (nivel, carrera), sub in grupo_ok.groupby([\"nivel\", \"carrera\"]):\n",
    "        # Solo consideramos conflicto si hay MATERIAS DISTINTAS en el mismo nivel/carrera\n",
    "        cods_unicos = sorted({c for c in sub[\"codigo\"] if pd.notna(c)})\n",
    "        if len(cods_unicos) > 1:\n",
    "            problemas.append(f\"Malla {carrera} – Nivel {int(nivel)}: {', '.join(cods_unicos)}\")\n",
    "\n",
    "    # Construir texto con bullets y saltos de línea (wrap en Excel)\n",
    "    observaciones[nombre] = (\"• \" + \"\\n• \".join(problemas)) if problemas else \"\"\n",
    "\n",
    "# Agregar columna Observaciones (sin borrar las demás columnas)\n",
    "profesores_df[\"Observaciones\"] = profesores_df[\"Nombre\"].map(observaciones)\n",
    "\n",
    "# ======== Exportar a Excel con wrap text y filtros ========\n",
    "output_file = \"outputs/Reporte_AsignaturasPorNivel.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
    "    sheet_name = \"Validación\"\n",
    "    profesores_df.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "    # Filtros por columna y congelar encabezado\n",
    "    n_rows, n_cols = profesores_df.shape\n",
    "    worksheet.autofilter(0, 0, n_rows, n_cols - 1)\n",
    "    worksheet.freeze_panes(1, 0)\n",
    "\n",
    "    # Formato wrap text para Observaciones\n",
    "    wrap_fmt = workbook.add_format({\n",
    "        \"text_wrap\": True,\n",
    "        \"valign\": \"top\"\n",
    "    })\n",
    "\n",
    "    # Ajuste de ancho para la columna Observaciones\n",
    "    obs_col_idx = list(profesores_df.columns).index(\"Observaciones\")\n",
    "    worksheet.set_column(obs_col_idx, obs_col_idx, 60, wrap_fmt)\n",
    "\n",
    "    # (Opcional) Ancho cómodo para el resto de columnas\n",
    "    # worksheet.set_column(0, n_cols - 2, 18)\n",
    "\n",
    "print(f\"✅ Archivo generado con observaciones en: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
